# Existing app.py contents go here.
# I will now insert both: 
# 1. The restored Single / Multi document mode menu
# 2. The chunking safeguard inside summarize_text()

import os
import time
import streamlit as st
import PyPDF2
from openai import OpenAI
import pandas as pd
import re

# Load secrets
PASSWORD_SECRET = st.secrets["STREAMLIT_PASSWORD"]
OPENAI_KEY = st.secrets["OPENAI_API_KEY"]

# Set up page
st.set_page_config(page_title="Legal PDF Summarizer")
st.title("üìÑ Legal PDF Summarizer")

# Password gate
password = st.text_input("Enter app password:", type="password")
if not password:
    st.stop()
if password != PASSWORD_SECRET:
    st.error("‚ùå Incorrect password")
    st.stop()

# Mode selection menu
mode = st.radio(
    "What would you like to do?",
    ["üîç Summarize a Single Document", "üìä Summarize and Compare Multiple Documents"]
)

# PDF text extraction helper
def extract_pdf_text(file):
    reader = PyPDF2.PdfReader(file)
    full_text = ""
    for page in reader.pages:
        full_text += page.extract_text() or ""
    return full_text.strip()

# Chunking helper
def chunk_text(text, max_chars=12000):
    chunks = []
    buf = []
    count = 0
    for para in text.split("\n"):
        if count + len(para) + 1 > max_chars:
            chunks.append("\n".join(buf).strip())
            buf, count = [], 0
        buf.append(para)
        count += len(para) + 1
    if buf:
        chunks.append("\n".join(buf).strip())
    return [c for c in chunks if c]

# Summarization function with chunking safeguard
def summarize_text(text):
    client = OpenAI(api_key=OPENAI_KEY)
    model = "gpt-4o-mini"
    chunks = chunk_text(text)

    partials = []
    for i, ck in enumerate(chunks, 1):
        with st.spinner(f"Summarizing chunk {i}/{len(chunks)}‚Ä¶"):
            resp = client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "You are a legal contract summarizer. For the given text, produce a concise, factual summary."
                        )
                    },
                    {"role": "user", "content": ck}
                ],
                temperature=0.2,
                max_tokens=500
            )
        partials.append(resp.choices[0].message.content.strip())
        time.sleep(0.8)  # prevent hitting token rate limit

    synthesis_prompt = (
        "Combine the following partial summaries into one structured summary with these sections:\n"
        "1. Parties\n2. Effective Date\n3. Term\n4. Confidential Information\n"
        "5. Obligations\n6. Jurisdiction\n7. Risk Flags\n\n"
        "Partial summaries:\n\n" + "\n\n".join(partials)
    )

    final = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a precise legal contract summarizer."},
            {"role": "user", "content": synthesis_prompt}
        ],
        temperature=0.2,
        max_tokens=800
    )
    return final.choices[0].message.content.strip()

# === Main Logic ===
if mode == "üîç Summarize a Single Document":
    uploaded_file = st.file_uploader("Upload a legal PDF", type=["pdf"])
    if uploaded_file:
        pdf_text = extract_pdf_text(uploaded_file)
        if not pdf_text:
            st.warning("‚ö†Ô∏è The uploaded PDF appears to be empty.")
        else:
            try:
                with st.spinner("üß† Summarizing document..."):
                    summary_output = summarize_text(pdf_text)
                st.subheader("üìÑ Summary Output")
                st.write(summary_output)
            except Exception as e:
                st.error(f"‚ùå Error during summarization:\n\n{e}")

elif mode == "üìä Summarize and Compare Multiple Documents":
    uploaded_files = st.file_uploader("Upload multiple legal PDFs", type=["pdf"], accept_multiple_files=True)

    if uploaded_files:
        summaries = {}
        for file in uploaded_files:
            text = extract_pdf_text(file)
            if text:
                try:
                    with st.spinner(f"Summarizing {file.name}..."):
                        summary = summarize_text(text)
                        summaries[file.name] = summary
                        if summaries:
                            st.subheader("üìä Comparison Table")

    sections = [
        "Parties",
        "Effective Date",
        "Term",
        "Confidential Information",
        "Obligations",
        "Jurisdiction",
        "Risk Flags"
    ]

    def extract_section(summary_text, section_name):
        pattern = rf"{section_name}.*?:([\s\S]*?)(?=\n[A-Z][a-z]+:|\n[A-Z][A-Z ]+:|$)"
        match = re.search(pattern, summary_text, re.IGNORECASE)
        return match.group(1).strip() if match else "Not specified"

    comparison_data = {section: [] for section in sections}
    file_labels = []

    for filename, summary in summaries.items():
        file_labels.append(filename)
        for section in sections:
            content = extract_section(summary, section)
            comparison_data[section].append(content)

    df = pd.DataFrame(comparison_data, index=file_labels)

    if not df.empty:
        st.dataframe(df.transpose())
    else:
        st.warning("‚ö†Ô∏è Could not extract structured sections from one or more summaries.")

    st.subheader("üóÇ Raw Summary Comparison")
    for filename, summary in summaries.items():
        with st.expander(f"üìÑ {filename}"):
            st.markdown(summary)

    # Always show raw summaries below as fallback
    st.subheader("üóÇ Raw Summary Comparison")
    for filename, summary in summaries.items():
        with st.expander(f"üìÑ {filename}"):
            st.markdown(summary)
                except Exception as e:
                    summaries[file.name] = f"‚ùå Error: {e}"
            else:
                summaries[file.name] = "‚ö†Ô∏è Empty or unreadable file."

        # Display comparison table
        st.subheader("üìä Comparison Table")

        sections = ["Parties", "Effective Date", "Term", "Confidential Information", "Obligations", "Jurisdiction", "Risk Flags"]
        import pandas as pd

        def extract_section(summary_text, section_name):
            import re
            pattern = rf"{section_name}[\s\S]*?(?=\n[A-Z1-9]|$)"
            match = re.search(pattern, summary_text, re.IGNORECASE)
            return match.group(0).strip() if match else "Not specified"

        data = {section: [] for section in sections}
        file_names = []

        for name, summary in summaries.items():
            file_names.append(name)
            for section in sections:
                content = extract_section(summary, section)
                data[section].append(content)

        df = pd.DataFrame(data, index=file_names)
        st.dataframe(df.transpose())
